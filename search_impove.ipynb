{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "enclosed-damages",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymssql\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "smooth-classroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_HOST = '*****'\n",
    "SQL_USER = '*****'\n",
    "SQL_PWD = '*****'\n",
    "SQL_DB = '*****'\n",
    "\n",
    "sql_connect = pymssql.connect(\n",
    "        server=SQL_HOST,\n",
    "        user=SQL_USER,\n",
    "        password=SQL_PWD,\n",
    "        database=SQL_DB,\n",
    "        as_dict=True,\n",
    "        charset=\"UTF-8\",\n",
    "        timeout=200\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "surgical-america",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor_sql = sql_connect.cursor()\n",
    "cursor_sql.execute(\"****\")\n",
    "data = cursor_sql.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "standing-emission",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Title</th>\n",
       "      <th>TitleEN</th>\n",
       "      <th>TitleSearch</th>\n",
       "      <th>TitleVN</th>\n",
       "      <th>TopTitle</th>\n",
       "      <th>State</th>\n",
       "      <th>Status</th>\n",
       "      <th>Image</th>\n",
       "      <th>Actors</th>\n",
       "      <th>...</th>\n",
       "      <th>AppID</th>\n",
       "      <th>Folder</th>\n",
       "      <th>ListOnfolder</th>\n",
       "      <th>EndTimeMovie</th>\n",
       "      <th>MPA</th>\n",
       "      <th>Producers</th>\n",
       "      <th>Parental</th>\n",
       "      <th>Is4K</th>\n",
       "      <th>Image_New</th>\n",
       "      <th>Image_4K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100020536</td>\n",
       "      <td>Amazon: Dòng Sông Của Mặt Trời (The Amazon Riv...</td>\n",
       "      <td>The Amazon River Of The Sun</td>\n",
       "      <td>Amazon: Dong Song Cua Mat Troi (The Amazon Riv...</td>\n",
       "      <td>Amazon: Dòng Sông Của Mặt Trời</td>\n",
       "      <td>Tài liệu</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>http://fboximages.fptplay.net.vn/VOD/Documenta...</td>\n",
       "      <td>Narrated</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>2100-01-01</td>\n",
       "      <td>PG</td>\n",
       "      <td>Razor Digital Entertainment</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>http://fboximages.fptplay.net.vn/VOD/Documenta...</td>\n",
       "      <td>http://fboximages.fptplay.net.vn/VOD/Documenta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100047007</td>\n",
       "      <td>Khai Quật Tổ Quỷ (Digging Up The Marrow)</td>\n",
       "      <td>Digging Up The Marrow</td>\n",
       "      <td>Khai Quat To Quy (Digging Up The Marrow)</td>\n",
       "      <td>Khai Quật Tổ Quỷ</td>\n",
       "      <td>Tài liệu</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>http://fboximages.fptplay.net.vn/VOD/Documenta...</td>\n",
       "      <td>Ray Wise, Adam Green, Will Barratt</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>16,300</td>\n",
       "      <td>2100-01-01</td>\n",
       "      <td>R</td>\n",
       "      <td>ArieScope Pictures</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>http://fboximages.fptplay.net.vn/VOD/Documenta...</td>\n",
       "      <td>http://fboximages.fptplay.net.vn/VOD/Documenta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100028086</td>\n",
       "      <td>Sóng Thần Nhật Bản Đã Xảy Ra Như Thế Nào? (Jap...</td>\n",
       "      <td>Japans Tsunami - How It Happened</td>\n",
       "      <td>Song Than Nhat Ban Da Xay Ra Nhu The Nao? (Jap...</td>\n",
       "      <td>Sóng Thần Nhật Bản Đã Xảy Ra Như Thế Nào?</td>\n",
       "      <td>Tài liệu</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>http://fboximages.fptplay.net.vn/VOD/Documenta...</td>\n",
       "      <td>Mark Strong, Roger Bilham, Simon Boxall</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>2100-01-01</td>\n",
       "      <td>PG</td>\n",
       "      <td>Pioneer Productions</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>http://fboximages.fptplay.net.vn/VOD/Documenta...</td>\n",
       "      <td>http://fboximages.fptplay.net.vn/VOD/Documenta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              Title  \\\n",
       "0  100020536  Amazon: Dòng Sông Của Mặt Trời (The Amazon Riv...   \n",
       "1  100047007           Khai Quật Tổ Quỷ (Digging Up The Marrow)   \n",
       "2  100028086  Sóng Thần Nhật Bản Đã Xảy Ra Như Thế Nào? (Jap...   \n",
       "\n",
       "                            TitleEN  \\\n",
       "0       The Amazon River Of The Sun   \n",
       "1             Digging Up The Marrow   \n",
       "2  Japans Tsunami - How It Happened   \n",
       "\n",
       "                                         TitleSearch  \\\n",
       "0  Amazon: Dong Song Cua Mat Troi (The Amazon Riv...   \n",
       "1           Khai Quat To Quy (Digging Up The Marrow)   \n",
       "2  Song Than Nhat Ban Da Xay Ra Nhu The Nao? (Jap...   \n",
       "\n",
       "                                     TitleVN  TopTitle  State  Status  \\\n",
       "0             Amazon: Dòng Sông Của Mặt Trời  Tài liệu      5       1   \n",
       "1                           Khai Quật Tổ Quỷ  Tài liệu      5       1   \n",
       "2  Sóng Thần Nhật Bản Đã Xảy Ra Như Thế Nào?  Tài liệu      5       1   \n",
       "\n",
       "                                               Image  \\\n",
       "0  http://fboximages.fptplay.net.vn/VOD/Documenta...   \n",
       "1  http://fboximages.fptplay.net.vn/VOD/Documenta...   \n",
       "2  http://fboximages.fptplay.net.vn/VOD/Documenta...   \n",
       "\n",
       "                                    Actors  ... AppID Folder ListOnfolder  \\\n",
       "0                                 Narrated  ...    21     16           16   \n",
       "1       Ray Wise, Adam Green, Will Barratt  ...    21     16       16,300   \n",
       "2  Mark Strong, Roger Bilham, Simon Boxall  ...    21     16           16   \n",
       "\n",
       "   EndTimeMovie MPA                    Producers  Parental Is4K  \\\n",
       "0    2100-01-01  PG  Razor Digital Entertainment         0    0   \n",
       "1    2100-01-01   R           ArieScope Pictures        16    0   \n",
       "2    2100-01-01  PG          Pioneer Productions         0    0   \n",
       "\n",
       "                                           Image_New  \\\n",
       "0  http://fboximages.fptplay.net.vn/VOD/Documenta...   \n",
       "1  http://fboximages.fptplay.net.vn/VOD/Documenta...   \n",
       "2  http://fboximages.fptplay.net.vn/VOD/Documenta...   \n",
       "\n",
       "                                            Image_4K  \n",
       "0  http://fboximages.fptplay.net.vn/VOD/Documenta...  \n",
       "1  http://fboximages.fptplay.net.vn/VOD/Documenta...  \n",
       "2  http://fboximages.fptplay.net.vn/VOD/Documenta...  \n",
       "\n",
       "[3 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.DataFrame(data)\n",
    "data_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "attempted-hungary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Amazon River Of The Sun',\n",
       " 'Digging Up The Marrow',\n",
       " 'Japans Tsunami - How It Happened']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_search = data_df[\"TitleEN\"].values.tolist()\n",
    "data_search[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "operating-realtor",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_search = [re.sub(r'[^a-z0-9 ]+','',i.lower()) for i in data_search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eight-crown",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the amazon river of the sun',\n",
       " 'digging up the marrow',\n",
       " 'japans tsunami  how it happened']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_search[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "reserved-homework",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "string = 'the amazon river of the sun'\n",
    "max_length = len(string)\n",
    "space_token = string.split()\n",
    "index = 0\n",
    "tokens = list()\n",
    "doc_tokens = dict()\n",
    "for token in space_token:\n",
    "    for i in range(index,index+10):\n",
    "        if i+1 <= max_length:\n",
    "            word = string[index:(i+1)]\n",
    "            tokens.append(word)\n",
    "            if word not in doc_tokens:\n",
    "                doc_tokens[word] = 1\n",
    "            else:\n",
    "                doc_tokens[word] += 1\n",
    "        else:\n",
    "            break\n",
    "    index += len(token) + 1\n",
    "    \n",
    "vocabs = set() \n",
    "    \n",
    "def edge_ngram(string, n=5):\n",
    "    global vocabs\n",
    "    max_length = len(string)\n",
    "    space_token = string.split()\n",
    "    index = 0\n",
    "    tokens = list()\n",
    "    doc_tokens = dict()\n",
    "    for token in space_token:\n",
    "        for i in range(index,index+10):\n",
    "            if i+1 <= max_length:\n",
    "                word = string[index:(i+1)]\n",
    "                tokens.append(word)\n",
    "                if word not in doc_tokens:\n",
    "                    doc_tokens[word] = 1\n",
    "                else:\n",
    "                    doc_tokens[word] += 1\n",
    "            else:\n",
    "                break\n",
    "        index += len(token) + 1\n",
    "    doc_tokens[\"term_counts\"] = len(tokens)\n",
    "    doc_tokens[\"doc_length\"] = len(string)\n",
    "    vocabs = vocabs.union(set(tokens))\n",
    "    return doc_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "light-entrance",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(data_search)\n",
    "term_counts = []\n",
    "\n",
    "for doc in data_search:\n",
    "    term_counts.append(edge_ngram(doc, n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "flexible-ivory",
   "metadata": {},
   "outputs": [],
   "source": [
    "term_count_in_document = dict()\n",
    "for term in vocabs:\n",
    "    term_count_in_document[term] = 0\n",
    "    for doc in term_counts:\n",
    "        if term in doc:\n",
    "            term_count_in_document[term] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "advance-times",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.530647985989493"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_length_doc = sum([i[\"doc_length\"] for i in term_counts])/len(term_counts)\n",
    "avg_length_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ranking-orleans",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(term, doc):\n",
    "    n = doc[\"term_counts\"]\n",
    "    term_count = 0\n",
    "    if term in doc:\n",
    "        term_count = doc[term]\n",
    "    return term_count/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "gorgeous-athens",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_norm(term, doc, avg_len, k=1.2, b=0.5):\n",
    "    return (tf(term, doc)*(k+1))/(tf(term, doc)+ k*(1 - b + b*doc[\"doc_length\"]/avg_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "nonprofit-handle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def idf(word, D):\n",
    "    d = 1\n",
    "    if word in D:\n",
    "        d = D[word]\n",
    "    return math.log2(N/d)\n",
    "\n",
    "\n",
    "def tf_idf(term, doc, D):\n",
    "    return tf(term, doc)*idf(term, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "visible-financing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf_norm(word, D):\n",
    "    d = 0\n",
    "    if word in D:\n",
    "        d = D[word]\n",
    "    return math.log2((N-d+0.5)/(d+0.5) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "compressed-calcium",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BM25(Q, doc):\n",
    "    return sum([idf_norm(w, doc)*tf_norm(w, doc, avg_length_doc) for w in Q])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "american-content",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "for i in range(len(term_counts)):\n",
    "    _1 = tf_idf('h', term_counts[i], term_count_in_document)\n",
    "    _2 = tf_idf('hu', term_counts[i], term_count_in_document)\n",
    "    _3 = tf_idf('hug', term_counts[i], term_count_in_document)\n",
    "    _4 = tf_idf('hug ', term_counts[i], term_count_in_document)\n",
    "    _5 = tf_idf('hug t', term_counts[i], term_count_in_document)\n",
    "    _6 = tf_idf('hug t', term_counts[i], term_count_in_document)\n",
    "    result.append(sum([_1, _2, _3, _4, _5, _6]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "addressed-pattern",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1, result2 = [], []\n",
    "for i in range(len(term_counts)):\n",
    "    score1 = tf_idf('trang ', term_counts[i], term_count_in_document)\n",
    "    score2 = tf_idf('trang', term_counts[i], term_count_in_document)\n",
    "    if score1 > 0:\n",
    "        result1.append({str(i):score1})\n",
    "    if score2 > 0:\n",
    "        result2.append({str(i):score2})\n",
    "    \n",
    "top_score1 = sorted(result1,key=lambda k: list(k.values())[0], reverse=True)\n",
    "top_1= top_score1[:5]\n",
    "top_score2 = sorted(result2,key=lambda k: list(k.values())[0], reverse=True)\n",
    "top_2= top_score2[:5]\n",
    "top_score = top_1 + top_2\n",
    "\n",
    "for res in top_score[:5]:\n",
    "    print(data_search[int(list(res.keys())[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "funny-professional",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BM25([\"hug t\", \"hug \", \"hug\", \"hu\", \"h\", \"t\"],term_counts[271])*term_counts[271][\"term_counts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "sticky-dining",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.058236181022911"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BM25([\"hug t\", \"hug \", \"hug\", \"hu\", \"h\", \"t\"],term_counts[631])*term_counts[631][\"term_counts\"]\n",
    "# term_counts[631]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "excited-samuel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trance\n",
      "lost transmissions\n",
      "train\n",
      "bureau of transformer\n",
      "the road the tragedy of one\n"
     ]
    }
   ],
   "source": [
    "result3 = []\n",
    "for i in range(len(term_counts)):\n",
    "    score3 = BM25([\"trang\", \"tran\", \"tra\", \"tr\", \"t\"],term_counts[i])*term_counts[i][\"term_counts\"]\n",
    "    if score3 > 0:\n",
    "        result3.append({str(i):score3})\n",
    "        \n",
    "top_score3 = sorted(result3,key=lambda k: list(k.values())[0], reverse=True)        \n",
    "for res in top_score3[:5]:\n",
    "    print(data_search[int(list(res.keys())[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abroad-profession",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
